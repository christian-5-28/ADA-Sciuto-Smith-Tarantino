{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Task-1.-Compiling-Ebola-Data\"><span class=\"toc-item-num\">Task 1.&nbsp;&nbsp;</span>Compiling Ebola Data</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-2.-RNA-Sequences\"><span class=\"toc-item-num\">Task 2.&nbsp;&nbsp;</span>RNA Sequences</a></div>\n",
    " <div class=\"lev1\"><a href=\"#Task-3.-Class-War-in-Titanic\"><span class=\"toc-item-num\">Task 3.&nbsp;&nbsp;</span>Class War in Titanic</a></div></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fake news term usage analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task we decided to consider three different period of time in order to see when the term \"fake news\" arise. We took the campaign period, the president-elect period and the presidency period. First of all we create a dataframe for each of these periods. Below you can see the helpers function that we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loading all the data in one dictionary and two lists: condensed and master and returning them.\n",
    "    You can access the json file from the dictionary\n",
    "    using the file name without the .json extension.\n",
    "    E.g.: all_data[\"condensed_2009\"]\n",
    "    \"\"\"\n",
    "\n",
    "    trump_tweets = glob.glob(\"trump_tweets/*.json\")\n",
    "\n",
    "    all_data = {}\n",
    "    condensed = []\n",
    "    master = []\n",
    "\n",
    "    for json_file in trump_tweets:\n",
    "\n",
    "        file = pd.read_json(json_file)\n",
    "        all_data[os.path.basename(json_file).replace(\".json\", \"\")] = file\n",
    "\n",
    "        if \"master\" in os.path.basename(json_file):\n",
    "            master.append(file)\n",
    "        else:\n",
    "            condensed.append(file)\n",
    "\n",
    "    return all_data, condensed, master\n",
    "\n",
    "\n",
    "\n",
    "def select_time_interval(df, date_column, start_datetime, end_datetime):\n",
    "    \"\"\"\n",
    "    returns a dataframe selected by a specific period of time\n",
    "    \"\"\"\n",
    "    return df[(df[date_column] >= start_datetime) & (df[date_column] <= end_datetime)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we create the three dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving all data from Trump's tweets dataset\n",
    "all_data, condensed, master = load_data()\n",
    "\n",
    "# getting the condensed version for year 2016 and 2017\n",
    "condensed_2016 = all_data[\"condensed_2016\"]\n",
    "condensed_2017 = all_data[\"condensed_2017\"]\n",
    "\n",
    "# creating a dataframe for campaign period\n",
    "cond_US_campaign_2016 = select_time_interval(condensed_2016, 'created_at',\n",
    "                                             np.datetime64('2016-02-01'), np.datetime64('2016-11-08'))\n",
    "\n",
    "cond_US_campaign_2016 = cond_US_campaign_2016.sort_values('created_at')\n",
    "\n",
    "\n",
    "# creating a dataframe for president elect period\n",
    "cond_pres_elect_df = select_time_interval(condensed_2016, 'created_at',\n",
    "                                          np.datetime64('2016-11-09'), np.datetime64('2016-12-31'))\n",
    "\n",
    "cond_pres_elect_df_2017 = select_time_interval(condensed_2017, 'created_at',\n",
    "                                               np.datetime64('2017-01-01'), np.datetime64('2017-01-20'))\n",
    "\n",
    "cond_pres_elect_df = cond_pres_elect_df.append(cond_pres_elect_df_2017)\n",
    "\n",
    "cond_pres_elect_df = cond_pres_elect_df.sort_values('created_at')\n",
    "\n",
    "\n",
    "\n",
    "# creating a dataframe for presidency period\n",
    "cond_president_period_df = select_time_interval(condensed_2017, 'created_at',\n",
    "                                                np.datetime64('2017-01-20'), np.datetime64('2017-11-05'))\n",
    "\n",
    "cond_president_period_df = cond_president_period_df.sort_values('created_at')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The campaign period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we will search in each tweets for the term \"fake news\". We used a simple regex and we do not consider case sensitive. We create a new column of boolean values 'fake_news_used' in our dataframe using the 'contains' method. After this we create useful columns with Month, week/year and day values in order to make a groupby with them and see some interesting patterns in the usage of the term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating the column with boolean values for the matches of the regex:\n",
    "cond_US_campaign_2016['fake_news_used'] = cond_US_campaign_2016['text'].str.contains('fake news|fakenews', case=False)\n",
    "\n",
    "# creating the columns 'Month', 'week/year' and 'Date'\n",
    "cond_US_campaign_2016['Month'] = cond_US_campaign_2016['created_at'].dt.month\n",
    "cond_US_campaign_2016['week/year'] = cond_US_campaign_2016['created_at'].apply(lambda x: \"%d/%d\" % (x.week, x.year))\n",
    "cond_US_campaign_2016['Date'] = cond_US_campaign_2016['created_at'].dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now first we count how many positive results we had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_US_campaign_2016['fake_news_used'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, during his campaign period, the 'fake news' did not appear in any of his tweets. In order to be sure we search for the words 'fake' and 'news' separately and these are the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '\"@ddpick18: @realDonaldTrump This Texan will be voting Trump March 1st. Cruz is a fake Texan!\"'\n",
      " '@elizabethforma Goofy Elizabeth Warren, sometimes referred to as Pocahontas because she faked the fact she is native American, is a lowlife!'\n",
      " '\"@JimVitari:  @ABC @washingtonpost we know they\\'re fake just like poles during primary. I\\'m sure u will crush #CrookedHillary in general\"'\n",
      " '\"@brazosboys: Hillary read \"sigh\" off the Teleprompter, She\\'s so fake she has to be told how to feel: https://t.co/ENXliW2m77 @FoxNews']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>fake_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>\"@ddpick18: @realDonaldTrump This Texan will b...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>@elizabethforma Goofy Elizabeth Warren, someti...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898</th>\n",
       "      <td>\"@JimVitari:  @ABC @washingtonpost we know the...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>\"@brazosboys: Hillary read \"sigh\" off the Tele...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  fake_usage\n",
       "3349  \"@ddpick18: @realDonaldTrump This Texan will b...        True\n",
       "2228  @elizabethforma Goofy Elizabeth Warren, someti...        True\n",
       "1898  \"@JimVitari:  @ABC @washingtonpost we know the...        True\n",
       "1897  \"@brazosboys: Hillary read \"sigh\" off the Tele...        True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for the word fake\n",
    "match_df = cond_US_campaign_2016.loc[:,['text']]\n",
    "match_df['fake_usage'] = cond_US_campaign_2016['text'].str.contains('fake', case=False)\n",
    "temp_df = match_df[match_df['fake_usage'] == True]\n",
    "\n",
    "print(str(temp_df.text.values))\n",
    "temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>news_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>I will be interviewed on @greta at 7:00 P.M. E...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>Dopey Mort Zuckerman, owner of the worthless @...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>Worthless @NYDailyNews, which dopey Mort Zucke...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>Like the worthless @NYDailyNews, looks like @p...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>There are no buyers for the worthless @NYDaily...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  news_usage\n",
       "3705  I will be interviewed on @greta at 7:00 P.M. E...        True\n",
       "3601  Dopey Mort Zuckerman, owner of the worthless @...        True\n",
       "3600  Worthless @NYDailyNews, which dopey Mort Zucke...        True\n",
       "3599  Like the worthless @NYDailyNews, looks like @p...        True\n",
       "3591  There are no buyers for the worthless @NYDaily...        True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for the word 'news'\n",
    "match_df = cond_US_campaign_2016.loc[:,['text']]\n",
    "match_df['news_usage'] = cond_US_campaign_2016['text'].str.contains('news', case=False)\n",
    "temp_df = match_df[match_df['news_usage'] == True]\n",
    "\n",
    "# showing the results\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of positive matches:\n",
    "temp_df.news_usage.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'news' term we found mostly tweets with hashtags of media or other tweets that are related with 'fake news' term.\n",
    "Therefore, we conlcude what we have said before, in the campaign period there is no sign of the 'fake news' term in his tweets. We can go ahead with the president-elect period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### President elect period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we repeat the same process that we have done for the campaign period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the column with boolean values for the matches of the regex:\n",
    "cond_pres_elect_df['fake_news_used'] = cond_pres_elect_df['text'].str.contains('fake news|fakenews', case=False)\n",
    "\n",
    "# creating the columns 'month', 'week/year' and 'date'\n",
    "cond_pres_elect_df['month'] = cond_pres_elect_df['created_at'].dt.month\n",
    "cond_pres_elect_df['week/year'] = cond_pres_elect_df['created_at'].apply(lambda x: \"%d/%d\" % (x.week, x.year))\n",
    "cond_pres_elect_df['date'] = cond_pres_elect_df['created_at'].dt.date\n",
    "\n",
    "# showing the number of positive matches:\n",
    "cond_pres_elect_df['fake_news_used'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have few positive matches, let's continue with the analysis:\n",
    "- first we display all the tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'Reports by @CNN that I will be working on The Apprentice during my Presidency, even part time, are ridiculous &amp; untrue - FAKE NEWS!'\n",
      " 'FAKE NEWS - A TOTAL POLITICAL WITCH HUNT!'\n",
      " 'RT @MichaelCohen212: I have never been to Prague in my life. #fakenews https://t.co/CMil9Rha3D'\n",
      " \"'BuzzFeed Runs Unverifiable Trump-Russia Claims' #FakeNews \\nhttps://t.co/d6daCFZHNh\"\n",
      " 'I win an election easily, a great \"movement\" is verified, and crooked opponents try to belittle our victory with FAKE NEWS. A sorry state!'\n",
      " 'Intelligence agencies should never have allowed this fake news to \"leak\" into the public. One last shot at me.Are we living in Nazi Germany?'\n",
      " \"We had a great News Conference at Trump Tower today. A couple of FAKE NEWS organizations were there but the people truly get what's going on\"\n",
      " '.@CNN is in a total meltdown with their FAKE NEWS because their ratings are tanking since election and their credibility will soon be gone!'\n",
      " 'Totally made up facts by sleazebag political operatives, both Democrats and Republicans - FAKE NEWS! Russia says nothing exists. Probably...'\n",
      " 'much worse - just look at Syria (red line), Crimea, Ukraine and the build-up of Russian nukes. Not good! Was this the leaker of Fake News?'\n",
      " \"to the U.S., but had nothing to do with TRUMP, is more FAKE NEWS. Ask top CEO's of those companies for real facts. Came back because of me!\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2016-12-10</td>\n",
       "      <td>Reports by @CNN that I will be working on The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>FAKE NEWS - A TOTAL POLITICAL WITCH HUNT!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>RT @MichaelCohen212: I have never been to Prag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>'BuzzFeed Runs Unverifiable Trump-Russia Claim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>I win an election easily, a great \"movement\" i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>2017-01-11</td>\n",
       "      <td>Intelligence agencies should never have allowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>We had a great News Conference at Trump Tower ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>2017-01-12</td>\n",
       "      <td>.@CNN is in a total meltdown with their FAKE N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>2017-01-13</td>\n",
       "      <td>Totally made up facts by sleazebag political o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>much worse - just look at Syria (red line), Cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2073</th>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>to the U.S., but had nothing to do with TRUMP,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                               text\n",
       "91    2016-12-10  Reports by @CNN that I will be working on The ...\n",
       "2123  2017-01-11          FAKE NEWS - A TOTAL POLITICAL WITCH HUNT!\n",
       "2122  2017-01-11  RT @MichaelCohen212: I have never been to Prag...\n",
       "2121  2017-01-11  'BuzzFeed Runs Unverifiable Trump-Russia Claim...\n",
       "2118  2017-01-11  I win an election easily, a great \"movement\" i...\n",
       "2117  2017-01-11  Intelligence agencies should never have allowe...\n",
       "2116  2017-01-12  We had a great News Conference at Trump Tower ...\n",
       "2112  2017-01-12  .@CNN is in a total meltdown with their FAKE N...\n",
       "2108  2017-01-13  Totally made up facts by sleazebag political o...\n",
       "2090  2017-01-16  much worse - just look at Syria (red line), Cr...\n",
       "2073  2017-01-18  to the U.S., but had nothing to do with TRUMP,..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_df = cond_pres_elect_df.loc[cond_pres_elect_df['fake_news_used'] == True, ['date','text']]\n",
    "match_df = match_df.sort_values('date')\n",
    "from IPython.display import display\n",
    "print(str(match_df.text.values))\n",
    "match_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We noticed that in this 11 tweets the fake news term was related mostly with CNN and Russia. Specially the rise of the term was due to release of a non-verified paper by Buzzfeed containing strong claims about Trump and Russia ties and possibility that Trump could be blackmailed by the Russian governement. He over reacted to this leak, attacking the intelligence agencies and trying to discredit the Media. For more information, here you have the story described by the New York Times: https://www.nytimes.com/2017/01/10/business/buzzfeed-donald-trump-russia.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Due to the small number of tweets with the 'fake news' term we can go ahead with the next period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presidency period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we prepare the dataframe creating the column for the match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the column with boolean values from the regex result:\n",
    "cond_president_period_df['fake_news_used'] = cond_president_period_df['text'].str.contains('fake news|fakenews', case=False)\n",
    "\n",
    "# showing the number of positive results:\n",
    "cond_president_period_df['fake_news_used'].sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Considered that we have a period of 10 month, we have an interesting number of postive matches, so we can start a deeper analysis conidering the months, the week/year and by date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding month, date and week/year columns in order to make groupby operations\n",
    "cond_president_period_df['Month'] = cond_president_period_df['created_at'].dt.month\n",
    "cond_president_period_df['date'] = cond_president_period_df['created_at'].dt.date\n",
    "cond_president_period_df['week/year'] = cond_president_period_df['created_at'].apply(lambda x: \"%d/%d\" % (x.week, x.year))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## still have to add the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis by week/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## still have to add the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## still have to add the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Washington Post dataset scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## still have to add the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## still have to add the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of source usage (android iPhone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## still have to add the analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
